{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ECoG/EEG Motor Imagery Classification with ATCNet + LoRA\n",
        "\n",
        "This notebook demonstrates:\n",
        "1. Loading ECoG/EEG data from .fif files (MNE format)\n",
        "2. Training ATCNet on base subjects\n",
        "3. Fine-tuning using LoRA on target subjects\n",
        "\n",
        "Dataset: High Gamma Motor Imagery dataset (MNE .fif format)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages if not available\n",
        "# !pip install mne pytorch-lightning torchmetrics scipy scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset Class for ECoG/EEG (.fif files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import mne\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "class MultiSubjectECoGDataset(Dataset):\n",
        "    def __init__(self, file_list, freq_band=(1, 100), remove_bad=True, scale=True, transform=None, time_range=None):\n",
        "        \"\"\"\n",
        "        PyTorch Dataset for loading multi-subject ECoG/EEG data from .fif files.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        file_list : list of str\n",
        "            List of .fif file paths.\n",
        "        freq_band : tuple, optional\n",
        "            Bandpass filter frequency range in Hz, e.g., (1, 100).\n",
        "        remove_bad : bool, optional\n",
        "            Remove bad channels marked in the data.\n",
        "        scale : bool, optional\n",
        "            Apply StandardScaler per channel.\n",
        "        transform : callable, optional\n",
        "            Optional transformation to apply to each sample.\n",
        "        time_range : tuple or None, optional\n",
        "            Time window (start_sec, end_sec) relative to event onset to extract. Example: (0.5, 3).\n",
        "        \"\"\"\n",
        "        self.transform = transform\n",
        "        self.data = []\n",
        "        self.labels = []\n",
        "        self.scale = scale\n",
        "        self.remove_bad = remove_bad\n",
        "        self.freq_band = freq_band\n",
        "        self.time_range = time_range\n",
        "\n",
        "        for file in file_list:\n",
        "            print(f'Loading and processing {file}')\n",
        "            self._load_subject_data(file)\n",
        "\n",
        "        self.data = np.array(self.data)  # (n_trials, n_channels, n_times)\n",
        "        self.labels = np.array(self.labels)\n",
        "        print(f\"Loaded {len(self.data)} trials from {len(file_list)} subjects.\")\n",
        "\n",
        "    def _load_subject_data(self, file_path):\n",
        "        # Load raw data\n",
        "        raw = mne.io.read_raw_fif(file_path, preload=True, verbose=False)\n",
        "        if self.remove_bad:\n",
        "            raw.pick_types(ecog=True, eeg=True, exclude='bads')\n",
        "        \n",
        "        # Apply bandpass filter\n",
        "        if self.freq_band:\n",
        "            raw.filter(self.freq_band[0], self.freq_band[1], fir_design='firwin', verbose=False)\n",
        "\n",
        "        # Get events and labels\n",
        "        events, event_id = mne.events_from_annotations(raw, verbose=False)\n",
        "        print(f\"  Found {len(events)} events, event_id mapping: {event_id}\")\n",
        "\n",
        "        # Filter out REST events (optional - keep only MI events)\n",
        "        mi_event_ids = {}\n",
        "        for name, code in event_id.items():\n",
        "            # Uncomment the line below to filter out rest events\n",
        "            # if 'rest' not in name.lower():\n",
        "            mi_event_ids[name] = code\n",
        "\n",
        "        if not mi_event_ids:\n",
        "            print(\"  No Motor Imagery events found in this file.\")\n",
        "            return\n",
        "\n",
        "        print(f\"  Using events: {list(mi_event_ids.keys())}\")\n",
        "\n",
        "        # Epoching\n",
        "        if self.time_range:\n",
        "            tmin, tmax = self.time_range\n",
        "        else:\n",
        "            tmin, tmax = 0, 4  # Default 4s trial length\n",
        "\n",
        "        epochs = mne.Epochs(\n",
        "            raw, events, event_id=mi_event_ids,\n",
        "            tmin=tmin, tmax=tmax,\n",
        "            baseline=None, preload=True, verbose=False\n",
        "        )\n",
        "\n",
        "        X = epochs.get_data()  # (n_trials, n_channels, n_times)\n",
        "        y = epochs.events[:, -1]  # Label indices\n",
        "\n",
        "        # Optional scaling per channel\n",
        "        if self.scale:\n",
        "            for ch in range(X.shape[1]):\n",
        "                scaler = StandardScaler()\n",
        "                X[:, ch, :] = scaler.fit_transform(X[:, ch, :])\n",
        "        \n",
        "        # Save data and labels\n",
        "        for trial, label in zip(X, y):\n",
        "            self.data.append(trial)\n",
        "            self.labels.append(label - 1)  # Zero-based labels\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sample = self.data[index]  # (n_channels, n_times)\n",
        "        label = self.labels[index]\n",
        "\n",
        "        # Convert to PyTorch tensor and add channel dimension (1, n_channels, n_times)\n",
        "        sample = torch.from_numpy(sample).float().unsqueeze(0)\n",
        "        label = torch.tensor(label).long()\n",
        "\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "\n",
        "        return sample, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test Dataset Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test with a subset of files\n",
        "test_file_list = [\n",
        "    \"/kaggle/input/high-gamma-dataset-fif/Subject 1/0/0-raw.fif\",\n",
        "]\n",
        "\n",
        "# Create test dataset\n",
        "test_dataset = MultiSubjectECoGDataset(\n",
        "    file_list=test_file_list,\n",
        "    freq_band=None,  # or (2, 40) for bandpass\n",
        "    time_range=(0.0, 4.0),\n",
        "    remove_bad=False,\n",
        "    scale=False\n",
        ")\n",
        "\n",
        "# Create test dataloader\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "# Check batch shape\n",
        "for samples, labels in test_loader:\n",
        "    print(\"Sample shape:\", samples.shape)  # (batch_size, 1, n_channels, n_times)\n",
        "    print(\"Labels:\", labels)\n",
        "    print(\"Value range:\", samples.min().item(), \"to\", samples.max().item())\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize Data Quality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import welch\n",
        "\n",
        "def compute_mean_psd(batch, fs=250, nperseg=256):\n",
        "    \"\"\"\n",
        "    Compute the mean PSD for each channel across the batch.\n",
        "    \"\"\"\n",
        "    batch_size, _, num_channels, segment_length = batch.shape\n",
        "    mean_psd_per_channel = []\n",
        "    freqs = None\n",
        "\n",
        "    for ch in range(num_channels):\n",
        "        psds = []\n",
        "        for i in range(batch_size):\n",
        "            signal_ch = batch[i, 0, ch, :].cpu().numpy()\n",
        "            f, pxx = welch(signal_ch, fs=fs, nperseg=nperseg)\n",
        "            psds.append(pxx)\n",
        "        psds = np.array(psds)\n",
        "        mean_psd = psds.mean(axis=0)\n",
        "        mean_psd_per_channel.append(mean_psd)\n",
        "        if freqs is None:\n",
        "            freqs = f\n",
        "    return freqs, mean_psd_per_channel\n",
        "\n",
        "def plot_mean_psd(freqs, mean_psd_per_channel):\n",
        "    \"\"\"\n",
        "    Plot the mean PSD curves for all channels.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    for ch, psd in enumerate(mean_psd_per_channel):\n",
        "        plt.semilogy(freqs, psd, alpha=0.6, label=f'Ch {ch+1}' if ch < 10 else None)\n",
        "    plt.xlabel('Frequency (Hz)')\n",
        "    plt.ylabel('PSD (V^2/Hz)')\n",
        "    plt.title('Mean Power Spectral Density per Channel')\n",
        "    if len(mean_psd_per_channel) <= 10:\n",
        "        plt.legend(loc='upper right')\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Compute and plot PSD\n",
        "for batch in test_loader:\n",
        "    samples, labels = batch\n",
        "    freqs, mean_psd = compute_mean_psd(samples, fs=250, nperseg=256)\n",
        "    plot_mean_psd(freqs, mean_psd)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Channel statistics\n",
        "for batch in test_loader:\n",
        "    samples, labels = batch\n",
        "    samples_squeezed = samples.squeeze(1)  # (batch_size, n_channels, n_times)\n",
        "    \n",
        "    channel_means = samples_squeezed.mean(dim=(0, 2)).numpy()\n",
        "    channel_stds = samples_squeezed.std(dim=(0, 2)).numpy()\n",
        "    \n",
        "    channels = np.arange(1, samples_squeezed.shape[1] + 1)\n",
        "    \n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.errorbar(channels, channel_means, yerr=channel_stds, fmt='o', capsize=5, color='steelblue')\n",
        "    plt.title(\"Mean ± STD per Channel (Averaged over Batch & Time)\")\n",
        "    plt.xlabel(\"Channel\")\n",
        "    plt.ylabel(\"Amplitude\")\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ATCNet Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ATCNet(nn.Module):\n",
        "    def __init__(self,\n",
        "                 in_channels: int = 1,\n",
        "                 num_classes: int = 4,\n",
        "                 num_windows: int = 3,\n",
        "                 num_electrodes: int = 22,\n",
        "                 conv_pool_size: int = 7,\n",
        "                 F1: int = 16,\n",
        "                 D: int = 2,\n",
        "                 tcn_kernel_size: int = 4,\n",
        "                 tcn_depth: int = 2,\n",
        "                 chunk_size: int = 1125):\n",
        "        super(ATCNet, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.num_classes = num_classes\n",
        "        self.num_windows = num_windows\n",
        "        self.num_electrodes = num_electrodes\n",
        "        self.pool_size = conv_pool_size\n",
        "        self.F1 = F1\n",
        "        self.D = D\n",
        "        self.tcn_kernel_size = tcn_kernel_size\n",
        "        self.tcn_depth = tcn_depth\n",
        "        self.chunk_size = chunk_size\n",
        "        F2 = F1*D\n",
        "\n",
        "        self.conv_block = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, F1, (1, int(chunk_size/2+1)),\n",
        "                      stride=1, padding='same', bias=False),\n",
        "            nn.BatchNorm2d(F1, False),\n",
        "            nn.Conv2d(F1, F2, (num_electrodes, 1), padding=0, groups=F1),\n",
        "            nn.BatchNorm2d(F2, False),\n",
        "            nn.ELU(),\n",
        "            nn.AvgPool2d((1, 8)),\n",
        "            nn.Dropout2d(0.1),\n",
        "            nn.Conv2d(F2, F2, (1, 16), bias=False, padding='same'),\n",
        "            nn.BatchNorm2d(F2, False),\n",
        "            nn.ELU(),\n",
        "            nn.AvgPool2d((1, self.pool_size)),\n",
        "            nn.Dropout2d(0.1)\n",
        "        )\n",
        "        self.__build_model()\n",
        "\n",
        "    def __build_model(self):\n",
        "        with torch.no_grad():\n",
        "            x = torch.zeros(2, self.in_channels,\n",
        "                            self.num_electrodes, self.chunk_size)\n",
        "            x = self.conv_block(x)\n",
        "            x = x[:, :, -1, :]\n",
        "            x = x.permute(0, 2, 1)\n",
        "            self.__chan_dim, self.__embed_dim = x.shape[1:]\n",
        "            self.win_len = self.__chan_dim - self.num_windows + 1\n",
        "\n",
        "            for i in range(self.num_windows):\n",
        "                st = i\n",
        "                end = x.shape[1] - self.num_windows+i+1\n",
        "                x2 = x[:, st:end, :]\n",
        "\n",
        "                self.__add_msa(i)\n",
        "                x2_ = self.get_submodule(\"msa\"+str(i))(x2, x2, x2)[0]\n",
        "                self.__add_msa_drop(i)\n",
        "                x2_ = self.get_submodule(\"msa_drop\"+str(i))(x2)\n",
        "                x2 = torch.add(x2, x2_)\n",
        "\n",
        "                for j in range(self.tcn_depth):\n",
        "                    self.__add_tcn((i+1)*j, x2.shape[1])\n",
        "                    out = self.get_submodule(\"tcn\"+str((i+1)*j))(x2)\n",
        "                    if x2.shape[1] != out.shape[1]:\n",
        "                        self.__add_recov(i)\n",
        "                        x2 = self.get_submodule(\"re\"+str(i))(x2)\n",
        "                    x2 = torch.add(x2, out)\n",
        "                    x2 = nn.ELU()(x2)\n",
        "                x2 = x2[:, -1, :]\n",
        "                self.__dense_dim = x2.shape[-1]\n",
        "                self.__add_dense(i)\n",
        "                x2 = self.get_submodule(\"dense\"+str(i))(x2)\n",
        "\n",
        "    def __add_msa(self, index: int):\n",
        "        self.add_module('msa'+str(index), nn.MultiheadAttention(\n",
        "            embed_dim=self.__embed_dim,\n",
        "            num_heads=2,\n",
        "            batch_first=True))\n",
        "\n",
        "    def __add_msa_drop(self, index):\n",
        "        self.add_module('msa_drop'+str(index), nn.Dropout(0.3))\n",
        "\n",
        "    def __add_tcn(self, index: int, num_electrodes: int):\n",
        "        self.add_module('tcn'+str(index),\n",
        "                        nn.Sequential(\n",
        "            nn.Conv1d(num_electrodes, 32,\n",
        "                      self.tcn_kernel_size, padding='same'),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.ELU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Conv1d(32, 32, self.tcn_kernel_size, padding='same'),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.ELU(),\n",
        "            nn.Dropout(0.3))\n",
        "        )\n",
        "\n",
        "    def __add_recov(self, index: int):\n",
        "        self.add_module('re'+str(index),\n",
        "                        nn.Conv1d(self.win_len, 32, 4, padding='same'))\n",
        "\n",
        "    def __add_dense(self, index: int):\n",
        "        self.add_module('dense'+str(index),\n",
        "                        nn.Linear(self.__dense_dim, self.num_classes))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_block(x)\n",
        "        x = x[:, :, -1, :]\n",
        "        x = x.permute(0, 2, 1)\n",
        "\n",
        "        for i in range(self.num_windows):\n",
        "            st = i\n",
        "            end = x.shape[1] - self.num_windows+i+1\n",
        "            x2 = x[:, st:end, :]\n",
        "            x2_ = self.get_submodule(\"msa\"+str(i))(x2, x2, x2)[0]\n",
        "            x2_ = self.get_submodule(\"msa_drop\"+str(i))(x2)\n",
        "            x2 = torch.add(x2, x2_)\n",
        "\n",
        "            for j in range(self.tcn_depth):\n",
        "                out = self.get_submodule(\"tcn\"+str((i+1)*j))(x2)\n",
        "                if x2.shape[1] != out.shape[1]:\n",
        "                    x2 = self.get_submodule(\"re\"+str(i))(x2)\n",
        "                x2 = torch.add(x2, out)\n",
        "                x2 = nn.ELU()(x2)\n",
        "            x2 = x2[:, -1, :]\n",
        "            x2 = self.get_submodule(\"dense\"+str(i))(x2)\n",
        "            if i == 0:\n",
        "                sw_concat = x2\n",
        "            else:\n",
        "                sw_concat = sw_concat.add(x2)\n",
        "\n",
        "        x = sw_concat/self.num_windows\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LoRA Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "class LoRALayer(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim, rank=8, alpha=16):\n",
        "        super().__init__()\n",
        "        self.rank = rank\n",
        "        self.alpha = alpha\n",
        "        self.scaling = alpha / rank\n",
        "        \n",
        "        self.lora_A = nn.Parameter(torch.zeros(rank, in_dim))\n",
        "        self.lora_B = nn.Parameter(torch.zeros(out_dim, rank))\n",
        "        \n",
        "        nn.init.kaiming_uniform_(self.lora_A, a=math.sqrt(5))\n",
        "        nn.init.zeros_(self.lora_B)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return (x @ self.lora_A.T @ self.lora_B.T) * self.scaling\n",
        "\n",
        "\n",
        "class LinearWithLoRA(nn.Module):\n",
        "    def __init__(self, linear_layer, rank=8, alpha=16):\n",
        "        super().__init__()\n",
        "        self.linear = linear_layer\n",
        "        self.lora = LoRALayer(\n",
        "            linear_layer.in_features,\n",
        "            linear_layer.out_features,\n",
        "            rank=rank,\n",
        "            alpha=alpha\n",
        "        )\n",
        "        \n",
        "        for param in self.linear.parameters():\n",
        "            param.requires_grad = False\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.linear(x) + self.lora(x)\n",
        "\n",
        "\n",
        "def add_lora_to_model(model, rank=8, alpha=16, target_modules=['dense']):\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "    \n",
        "    for name, module in model.named_modules():\n",
        "        should_add_lora = any(target in name for target in target_modules)\n",
        "        \n",
        "        if should_add_lora and isinstance(module, nn.Linear):\n",
        "            parent_name = '.'.join(name.split('.')[:-1])\n",
        "            child_name = name.split('.')[-1]\n",
        "            \n",
        "            if parent_name:\n",
        "                parent = model.get_submodule(parent_name)\n",
        "            else:\n",
        "                parent = model\n",
        "            \n",
        "            lora_layer = LinearWithLoRA(module, rank=rank, alpha=alpha)\n",
        "            setattr(parent, child_name, lora_layer)\n",
        "            print(f\"Added LoRA to: {name}\")\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "def count_parameters(model):\n",
        "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    total = sum(p.numel() for p in model.parameters())\n",
        "    return trainable, total"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Trainer Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import logging\n",
        "from typing import Any, Dict, List, Tuple, Union\n",
        "import pytorch_lightning as pl\n",
        "import torchmetrics\n",
        "from torchmetrics import MetricCollection\n",
        "\n",
        "_EVALUATE_OUTPUT = List[Dict[str, float]]\n",
        "log = logging.getLogger('ecog_training')\n",
        "\n",
        "def classification_metrics(metric_list: List[str], num_classes: int):\n",
        "    allowed_metrics = ['precision', 'recall', 'f1score', 'accuracy', 'matthews', 'auroc', 'kappa']\n",
        "    for metric in metric_list:\n",
        "        if metric not in allowed_metrics:\n",
        "            raise ValueError(f\"{metric} is not allowed.\")\n",
        "    \n",
        "    metric_dict = {\n",
        "        'accuracy': torchmetrics.Accuracy(task='multiclass', num_classes=num_classes, top_k=1),\n",
        "        'precision': torchmetrics.Precision(task='multiclass', average='macro', num_classes=num_classes),\n",
        "        'recall': torchmetrics.Recall(task='multiclass', average='macro', num_classes=num_classes),\n",
        "        'f1score': torchmetrics.F1Score(task='multiclass', average='macro', num_classes=num_classes),\n",
        "        'matthews': torchmetrics.MatthewsCorrCoef(task='multiclass', num_classes=num_classes),\n",
        "        'auroc': torchmetrics.AUROC(task='multiclass', num_classes=num_classes),\n",
        "        'kappa': torchmetrics.CohenKappa(task='multiclass', num_classes=num_classes)\n",
        "    }\n",
        "    metrics = [metric_dict[name] for name in metric_list]\n",
        "    return MetricCollection(metrics)\n",
        "\n",
        "\n",
        "class ClassifierTrainer(pl.LightningModule):\n",
        "    def __init__(self, model: nn.Module, num_classes: int, lr: float = 1e-3,\n",
        "                 weight_decay: float = 0.0, devices: int = 1, accelerator: str = \"cpu\",\n",
        "                 verbose: bool = True, metrics: List[str] = [\"accuracy\"]):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.num_classes = num_classes\n",
        "        self.lr = lr\n",
        "        self.weight_decay = weight_decay\n",
        "        self.devices = devices\n",
        "        self.accelerator = accelerator\n",
        "        self.metrics = metrics\n",
        "        self.ce_fn = nn.CrossEntropyLoss()\n",
        "        self.verbose = verbose\n",
        "        self.init_metrics(metrics, num_classes)\n",
        "\n",
        "    def init_metrics(self, metrics: List[str], num_classes: int) -> None:\n",
        "        self.train_loss = torchmetrics.MeanMetric()\n",
        "        self.val_loss = torchmetrics.MeanMetric()\n",
        "        self.test_loss = torchmetrics.MeanMetric()\n",
        "        self.train_metrics = classification_metrics(metrics, num_classes)\n",
        "        self.val_metrics = classification_metrics(metrics, num_classes)\n",
        "        self.test_metrics = classification_metrics(metrics, num_classes)\n",
        "\n",
        "    def fit(self, train_loader: DataLoader, val_loader: DataLoader,\n",
        "            max_epochs: int = 300, *args, **kwargs) -> Any:\n",
        "        trainer = pl.Trainer(devices=self.devices, accelerator=self.accelerator,\n",
        "                             max_epochs=max_epochs, *args, **kwargs)\n",
        "        return trainer.fit(self, train_loader, val_loader)\n",
        "\n",
        "    def test(self, test_loader: DataLoader, *args, **kwargs) -> _EVALUATE_OUTPUT:\n",
        "        trainer = pl.Trainer(devices=self.devices, accelerator=self.accelerator,\n",
        "                             *args, **kwargs)\n",
        "        return trainer.test(self, test_loader)\n",
        "\n",
        "    def forward(self, x: torch.Tensor, *args, **kwargs) -> torch.Tensor:\n",
        "        return self.model(x, *args, **kwargs)\n",
        "\n",
        "    def training_step(self, batch: Tuple[torch.Tensor], batch_idx: int) -> torch.Tensor:\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = self.ce_fn(y_hat, y)\n",
        "        if self.verbose:\n",
        "            self.log(\"train_loss\", self.train_loss(loss),\n",
        "                     prog_bar=True, on_epoch=False, logger=False, on_step=True)\n",
        "            for i, metric_value in enumerate(self.train_metrics.values()):\n",
        "                self.log(f\"train_{self.metrics[i]}\", metric_value(y_hat, y),\n",
        "                         prog_bar=True, on_epoch=False, logger=False, on_step=True)\n",
        "        return loss\n",
        "\n",
        "    def on_train_epoch_end(self) -> None:\n",
        "        if self.verbose:\n",
        "            self.log(\"train_loss\", self.train_loss.compute(),\n",
        "                     prog_bar=False, on_epoch=True, on_step=False, logger=True)\n",
        "            for i, metric_value in enumerate(self.train_metrics.values()):\n",
        "                self.log(f\"train_{self.metrics[i]}\", metric_value.compute(),\n",
        "                         prog_bar=False, on_epoch=True, on_step=False, logger=True)\n",
        "        self.train_loss.reset()\n",
        "        self.train_metrics.reset()\n",
        "\n",
        "    def validation_step(self, batch: Tuple[torch.Tensor], batch_idx: int) -> torch.Tensor:\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = self.ce_fn(y_hat, y)\n",
        "        self.val_loss.update(loss)\n",
        "        self.val_metrics.update(y_hat, y)\n",
        "        return loss\n",
        "\n",
        "    def on_validation_epoch_end(self) -> None:\n",
        "        if self.verbose:\n",
        "            self.log(\"val_loss\", self.val_loss.compute(),\n",
        "                     prog_bar=False, on_epoch=True, on_step=False, logger=True)\n",
        "            for i, metric_value in enumerate(self.val_metrics.values()):\n",
        "                self.log(f\"val_{self.metrics[i]}\", metric_value.compute(),\n",
        "                         prog_bar=False, on_epoch=True, on_step=False, logger=True)\n",
        "        self.val_loss.reset()\n",
        "        self.val_metrics.reset()\n",
        "\n",
        "    def test_step(self, batch: Tuple[torch.Tensor], batch_idx: int) -> torch.Tensor:\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = self.ce_fn(y_hat, y)\n",
        "        self.test_loss.update(loss)\n",
        "        self.test_metrics.update(y_hat, y)\n",
        "        return loss\n",
        "\n",
        "    def on_test_epoch_end(self) -> None:\n",
        "        if self.verbose:\n",
        "            self.log(\"test_loss\", self.test_loss.compute(),\n",
        "                     prog_bar=False, on_epoch=True, on_step=False, logger=True)\n",
        "            for i, metric_value in enumerate(self.test_metrics.values()):\n",
        "                self.log(f\"test_{self.metrics[i]}\", metric_value.compute(),\n",
        "                         prog_bar=False, on_epoch=True, on_step=False, logger=True)\n",
        "        self.test_loss.reset()\n",
        "        self.test_metrics.reset()\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        parameters = list(self.model.parameters())\n",
        "        trainable_parameters = list(filter(lambda p: p.requires_grad, parameters))\n",
        "        optimizer = torch.optim.Adam(trainable_parameters,\n",
        "                                     lr=self.lr,\n",
        "                                     weight_decay=self.weight_decay)\n",
        "        return optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase 1: Base Model Training\n",
        "\n",
        "Train on base subjects (e.g., Subject 2-14)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dataset configuration\n",
        "DATA_PREFIX = \"/kaggle/input/high-gamma-dataset-fif/\"\n",
        "\n",
        "# Base training subjects (all except Subject 1)\n",
        "base_train_files = [\n",
        "    f\"{DATA_PREFIX}Subject 2/0/0-raw.fif\",\n",
        "    f\"{DATA_PREFIX}Subject 2/1/1-raw.fif\",\n",
        "    f\"{DATA_PREFIX}Subject 3/0/0-raw.fif\",\n",
        "    f\"{DATA_PREFIX}Subject 3/1/1-raw.fif\",\n",
        "    # Add more base subjects...\n",
        "]\n",
        "\n",
        "# Validation: Subject 1, session 1\n",
        "base_val_files = [\n",
        "    f\"{DATA_PREFIX}Subject 1/1/1-raw.fif\",\n",
        "]\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"PHASE 1: BASE MODEL TRAINING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Create datasets with preprocessing\n",
        "base_train_dataset = MultiSubjectECoGDataset(\n",
        "    file_list=base_train_files,\n",
        "    freq_band=(2, 40),  # Bandpass filter\n",
        "    time_range=(0.0, 4.0),\n",
        "    remove_bad=True,\n",
        "    scale=True  # StandardScaler per channel\n",
        ")\n",
        "\n",
        "base_val_dataset = MultiSubjectECoGDataset(\n",
        "    file_list=base_val_files,\n",
        "    freq_band=(2, 40),\n",
        "    time_range=(0.0, 4.0),\n",
        "    remove_bad=True,\n",
        "    scale=True\n",
        ")\n",
        "\n",
        "# Get dataset info\n",
        "sample_shape = base_train_dataset[0][0].shape\n",
        "num_channels = sample_shape[1]\n",
        "chunk_size = sample_shape[2]\n",
        "num_classes = len(np.unique(base_train_dataset.labels))\n",
        "\n",
        "print(f\"\\nDataset info:\")\n",
        "print(f\"  Number of channels: {num_channels}\")\n",
        "print(f\"  Chunk size: {chunk_size}\")\n",
        "print(f\"  Number of classes: {num_classes}\")\n",
        "\n",
        "# Create dataloaders\n",
        "batch_size = 32\n",
        "base_train_loader = DataLoader(base_train_dataset, batch_size=batch_size, shuffle=True)\n",
        "base_val_loader = DataLoader(base_val_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize base model\n",
        "base_model = ATCNet(\n",
        "    in_channels=1,\n",
        "    num_classes=num_classes,\n",
        "    num_windows=3,\n",
        "    num_electrodes=num_channels,\n",
        "    chunk_size=chunk_size,\n",
        "    F1=16,\n",
        "    D=2\n",
        ")\n",
        "\n",
        "trainable, total = count_parameters(base_model)\n",
        "print(f\"\\nBase model parameters:\")\n",
        "print(f\"  Trainable: {trainable:,}\")\n",
        "print(f\"  Total: {total:,}\")\n",
        "print(f\"  Percentage trainable: {100*trainable/total:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train base model\n",
        "device = 'gpu' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "base_trainer = ClassifierTrainer(\n",
        "    base_model,\n",
        "    num_classes=num_classes,\n",
        "    lr=1e-3,\n",
        "    metrics=[\"accuracy\"],\n",
        "    accelerator=device\n",
        ")\n",
        "\n",
        "print(\"\\nTraining base model...\")\n",
        "base_trainer.fit(base_train_loader, base_val_loader, max_epochs=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save base model\n",
        "torch.save(base_model.state_dict(), 'ecog_atcnet_base_model.pt')\n",
        "print(\"\\nBase model saved to 'ecog_atcnet_base_model.pt'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase 2: LoRA Fine-tuning\n",
        "\n",
        "Fine-tune on Subject 1, Session 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PHASE 2: LoRA FINE-TUNING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Load base model\n",
        "lora_model = ATCNet(\n",
        "    in_channels=1,\n",
        "    num_classes=num_classes,\n",
        "    num_windows=3,\n",
        "    num_electrodes=num_channels,\n",
        "    chunk_size=chunk_size,\n",
        "    F1=16,\n",
        "    D=2\n",
        ")\n",
        "\n",
        "lora_model.load_state_dict(torch.load('ecog_atcnet_base_model.pt'))\n",
        "print(\"\\nLoaded pre-trained base model\")\n",
        "\n",
        "# Add LoRA adapters\n",
        "lora_rank = 8\n",
        "lora_alpha = 16\n",
        "print(f\"\\nAdding LoRA adapters (rank={lora_rank}, alpha={lora_alpha})...\")\n",
        "lora_model = add_lora_to_model(lora_model, rank=lora_rank, alpha=lora_alpha, target_modules=['dense'])\n",
        "\n",
        "trainable, total = count_parameters(lora_model)\n",
        "print(f\"\\nLoRA model parameters:\")\n",
        "print(f\"  Trainable: {trainable:,}\")\n",
        "print(f\"  Total: {total:,}\")\n",
        "print(f\"  Percentage trainable: {100*trainable/total:.2f}%\")\n",
        "print(f\"  Parameter reduction: {100*(1-trainable/total):.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fine-tuning data: Subject 1, Session 0\n",
        "lora_train_files = [\n",
        "    f\"{DATA_PREFIX}Subject 1/0/0-raw.fif\",\n",
        "]\n",
        "\n",
        "# Validation: Subject 1, Session 1\n",
        "lora_val_files = [\n",
        "    f\"{DATA_PREFIX}Subject 1/1/1-raw.fif\",\n",
        "]\n",
        "\n",
        "lora_train_dataset = MultiSubjectECoGDataset(\n",
        "    file_list=lora_train_files,\n",
        "    freq_band=(2, 40),\n",
        "    time_range=(0.0, 4.0),\n",
        "    remove_bad=True,\n",
        "    scale=True\n",
        ")\n",
        "\n",
        "lora_val_dataset = MultiSubjectECoGDataset(\n",
        "    file_list=lora_val_files,\n",
        "    freq_band=(2, 40),\n",
        "    time_range=(0.0, 4.0),\n",
        "    remove_bad=True,\n",
        "    scale=True\n",
        ")\n",
        "\n",
        "lora_train_loader = DataLoader(lora_train_dataset, batch_size=32, shuffle=True)\n",
        "lora_val_loader = DataLoader(lora_val_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fine-tune with LoRA\n",
        "lora_trainer = ClassifierTrainer(\n",
        "    lora_model,\n",
        "    num_classes=num_classes,\n",
        "    lr=5e-4,  # Higher LR for LoRA\n",
        "    metrics=[\"accuracy\"],\n",
        "    accelerator=device\n",
        ")\n",
        "\n",
        "print(\"\\nFine-tuning with LoRA on Subject 1...\")\n",
        "lora_trainer.fit(lora_train_loader, lora_val_loader, max_epochs=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save LoRA model\n",
        "torch.save(lora_model.state_dict(), 'ecog_atcnet_lora_subject1.pt')\n",
        "print(\"\\nLoRA fine-tuned model saved to 'ecog_atcnet_lora_subject1.pt'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluation & Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"EVALUATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Test base model (without fine-tuning)\n",
        "print(\"\\n[Base Model - No Fine-tuning on Subject 1]\")\n",
        "base_test_model = ATCNet(\n",
        "    in_channels=1,\n",
        "    num_classes=num_classes,\n",
        "    num_windows=3,\n",
        "    num_electrodes=num_channels,\n",
        "    chunk_size=chunk_size,\n",
        "    F1=16,\n",
        "    D=2\n",
        ")\n",
        "base_test_model.load_state_dict(torch.load('ecog_atcnet_base_model.pt'))\n",
        "\n",
        "base_test_trainer = ClassifierTrainer(\n",
        "    base_test_model,\n",
        "    num_classes=num_classes,\n",
        "    metrics=[\"accuracy\"],\n",
        "    accelerator=device\n",
        ")\n",
        "base_results = base_test_trainer.test(lora_val_loader)\n",
        "\n",
        "# Test LoRA fine-tuned model\n",
        "print(\"\\n[LoRA Fine-tuned Model]\")\n",
        "lora_results = lora_trainer.test(lora_val_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parameter comparison visualization\n",
        "base_trainable, base_total = count_parameters(base_test_model)\n",
        "lora_trainable, lora_total = count_parameters(lora_model)\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Parameter comparison\n",
        "models = ['Base Model\\n(Full Fine-tuning)', 'LoRA Model\\n(Adapter Fine-tuning)']\n",
        "trainable_params = [base_trainable, lora_trainable]\n",
        "frozen_params = [base_total - base_trainable, lora_total - lora_trainable]\n",
        "\n",
        "x = range(len(models))\n",
        "width = 0.5\n",
        "\n",
        "ax1.bar(x, frozen_params, width, label='Frozen', color='lightgray')\n",
        "ax1.bar(x, trainable_params, width, bottom=frozen_params, label='Trainable', color='cornflowerblue')\n",
        "ax1.set_ylabel('Number of Parameters', fontsize=12)\n",
        "ax1.set_title('Parameter Comparison', fontsize=14, fontweight='bold')\n",
        "ax1.set_xticks(x)\n",
        "ax1.set_xticklabels(models)\n",
        "ax1.legend(fontsize=10)\n",
        "ax1.grid(axis='y', alpha=0.3)\n",
        "\n",
        "for i, (train, total) in enumerate([(base_trainable, base_total), (lora_trainable, lora_total)]):\n",
        "    ax1.text(i, total + max(trainable_params)*0.02, f'{100*train/total:.1f}%\\ntrainable', \n",
        "             ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
        "\n",
        "# Training efficiency\n",
        "reduction = 100 * (1 - lora_trainable / base_trainable)\n",
        "bars = ax2.bar(['Full Fine-tuning', 'LoRA Fine-tuning'], [100, 100 - reduction], \n",
        "               color=['coral', 'seagreen'], width=0.6)\n",
        "ax2.set_ylabel('Relative Training Cost (%)', fontsize=12)\n",
        "ax2.set_title('Training Efficiency Gain', fontsize=14, fontweight='bold')\n",
        "ax2.set_ylim([0, 120])\n",
        "ax2.grid(axis='y', alpha=0.3)\n",
        "\n",
        "ax2.text(0, 105, '100%', ha='center', fontsize=12, fontweight='bold')\n",
        "ax2.text(1, 100 - reduction + 5, f'{100-reduction:.1f}%', ha='center', fontsize=12, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('ecog_lora_comparison.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"SUMMARY\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"LoRA reduces trainable parameters by {reduction:.2f}%\")\n",
        "print(f\"Base model: {base_trainable:,} trainable params\")\n",
        "print(f\"LoRA model: {lora_trainable:,} trainable params\")\n",
        "print(f\"\\nMemory saving: ~{reduction:.1f}% during fine-tuning\")\n",
        "print(f\"Training speed: ~{reduction/100:.1f}x faster (fewer gradients to compute)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This notebook demonstrated:\n",
        "\n",
        "1. **ECoG/EEG Data Loading**: Used MNE to load .fif files with proper preprocessing\n",
        "2. **Base Training**: Trained ATCNet on multiple subjects (Subject 2-N)\n",
        "3. **LoRA Adaptation**: Added low-rank adapters to classification layers\n",
        "4. **Subject-Specific Fine-tuning**: Fine-tuned only LoRA parameters on Subject 1\n",
        "5. **Evaluation**: Compared base vs. LoRA fine-tuned performance\n",
        "\n",
        "**Key Benefits for ECoG/EEG:**\n",
        "- Efficient subject-specific adaptation\n",
        "- Preserves general features learned from multiple subjects\n",
        "- ~99% parameter reduction during fine-tuning\n",
        "- Can store multiple subject-specific adapters with minimal storage\n",
        "- Useful for clinical applications with limited subject data\n",
        "\n",
        "**Next Steps:**\n",
        "- Fine-tune LoRA adapters for each subject separately\n",
        "- Experiment with different frequency bands\n",
        "- Target different layers (TCN, attention) with LoRA\n",
        "- Compare with full fine-tuning on more subjects"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
